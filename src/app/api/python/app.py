import os
import gc
import torch
import numpy as np
from flask import Flask, request, jsonify
from flask_cors import CORS
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
import lime.lime_text
lime.lime_text.multiprocessing = None  # Disable multiprocessing
from lime.lime_text import LimeTextExplainer
from scipy.spatial.distance import mahalanobis # For Mahalanobis distance

# Initialize Flask app
app = Flask(__name__)
CORS(app)

# ==================== Global Model Setup ====================
model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "models")
tokenizer = None
model = None
explainer = None
# For OOD Detection
in_distribution_mean = None
in_distribution_inv_covariance = None
MAHALANOBIS_THRESHOLD = 26.0 # Placeholder threshold

def load_model_and_ood_stats():
    global tokenizer, model, explainer, in_distribution_mean, in_distribution_inv_covariance
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model directory not found: {model_path}")

    print(f"Loading model files: {os.listdir(model_path)}")
    tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
    model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True, output_hidden_states=True)
    model.to("cpu").eval()

    explainer = LimeTextExplainer(
        class_names=["Verified", "Fake", "I don't know"],
        bow=False,
        mask_string=''
    )
    print("Model, tokenizer, and explainer loaded.")

    # Load pre-computed in-distribution statistics
    # These files (mean.npy and inv_covariance.npy) would be generated by a separate script
    # using a representative in-distribution dataset.
    stats_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "ood_stats")
    mean_path = os.path.join(stats_path, "mean.npy")
    inv_cov_path = os.path.join(stats_path, "inv_covariance.npy")

    if os.path.exists(mean_path) and os.path.exists(inv_cov_path):
        try:
            in_distribution_mean = np.load(mean_path)
            in_distribution_inv_covariance = np.load(inv_cov_path)
            print("In-distribution OOD statistics loaded.")
        except Exception as e:
            print(f"Error loading OOD statistics: {e}. OOD detection might not work correctly.")
            # Create dummy placeholders if loading fails, to allow the app to run
            # The actual dimension would depend on the BERT model's hidden size
            # Assuming BERT base: 768
            bert_hidden_size = model.config.hidden_size
            in_distribution_mean = np.zeros(bert_hidden_size)
            in_distribution_inv_covariance = np.eye(bert_hidden_size)
            print("Using dummy OOD statistics.")
    else:
        print("OOD statistics files not found. Creating dummy placeholders.")
        # Create dummy placeholders if files don't exist
        bert_hidden_size = model.config.hidden_size
        in_distribution_mean = np.zeros(bert_hidden_size)
        in_distribution_inv_covariance = np.eye(bert_hidden_size)
        print(f"Dummy OOD statistics created with hidden size: {bert_hidden_size}.")


# Load at startup
load_model_and_ood_stats()


def prediction_function_for_lime(texts):
    # This is specifically for LIME, which expects probability outputs
    if isinstance(texts, str):
        texts = [texts]
    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors="pt")
    inputs = {k: v.to("cpu") for k, v in inputs.items()}
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=1)
    return probs.cpu().numpy()


def bert_predict_with_embeddings(text):
    inputs = tokenizer(text, truncation=True, padding=True, max_length=512, return_tensors="pt")
    inputs = {k: v.to("cpu") for k, v in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=1)
        pred_label = torch.argmax(probs, dim=1).item()

        # Extract last hidden state (CLS token embedding)
        # outputs.hidden_states is a tuple of tensors, one for each layer + embeddings
        # The last one is model.config.num_hidden_layers
        last_hidden_state = outputs.hidden_states[-1]
        # Typically, the [CLS] token embedding (first token) is used for sentence-level tasks
        cls_embedding = last_hidden_state[:, 0, :].cpu().numpy()

    return pred_label, probs.cpu().numpy()[0], cls_embedding


def calculate_mahalanobis(embedding, mean, inv_covariance):
    if embedding is None or mean is None or inv_covariance is None:
        return np.inf # Or handle error appropriately
    # Ensure embedding is 1D
    if embedding.ndim > 1:
        embedding = embedding.squeeze()
    # Mahalanobis distance calculation
    # scipy.spatial.distance.mahalanobis takes u, v, VI where VI is inverse covariance
    # u is the point, v is the mean
    try:
        dist = mahalanobis(embedding, mean, inv_covariance)
    except Exception as e:
        print(f"Error calculating Mahalanobis distance: {e}")
        dist = np.inf # Return a high value on error
    return dist


def LIME_Algorithm(input_text):
    # Use the LIME-specific prediction function
    exp = explainer.explain_instance(
        input_text,
        prediction_function_for_lime, # Changed here
        num_features=5,
        num_samples=1000
    )
    features = [{'feature': f, 'weight': w} for f, w in exp.as_list()]
    fidelity = getattr(exp, 'score', None)

    del exp
    gc.collect()
    torch.cuda.empty_cache() if torch.cuda.is_available() else None

    return features, fidelity


@app.route('/', methods=['POST'])
def POST_Method():
    try:
        data = request.get_json(force=True)
        input_text = data.get('input')
        if not input_text:
            return jsonify({'error': "'input' field is required"}), 400

        # Get prediction, probabilities, and embeddings
        pred_label, probs, embedding = bert_predict_with_embeddings(input_text)

        # OOD Detection using Mahalanobis Distance
        if in_distribution_mean is not None and in_distribution_inv_covariance is not None:
            mahalanobis_dist = calculate_mahalanobis(embedding, in_distribution_mean, in_distribution_inv_covariance)
            print(f"Input: '{input_text[:50]}...', Mahalanobis Distance: {mahalanobis_dist:.2f}")

            if mahalanobis_dist > MAHALANOBIS_THRESHOLD:
                print(f"OOD detected (Distance: {mahalanobis_dist:.2f} > Threshold: {MAHALANOBIS_THRESHOLD}). Responding 'I don't know'.")
                return jsonify({'AIResponse': "I don't know", 'LIMEOutput': [], 'rawPredictions': probs.tolist(), 'ood_score': mahalanobis_dist}), 200
        else:
            print("OOD stats not available, skipping Mahalanobis check.")


        # If not OOD, proceed with original logic (softmax thresholding and LIME)
        # The problem statement implies BERT has high *confidence* (softmax) on OOD,
        # so Mahalanobis should ideally catch it first.
        # We can keep the softmax threshold as a secondary check or remove it if Mahalanobis is deemed sufficient.
        # For now, let's keep it.
        if pred_label == 2 or probs.max() < 0.7: # Class 2 is "I don't know"
            # Check if this was already an "I don't know" from the model's direct output
            # or low confidence even if not OOD by Mahalanobis.
            ai_label = "I don't know"
            # If it's "I don't know" from the model, LIME might not be meaningful or could error.
            # So, return empty LIME for this case too.
            return jsonify({'AIResponse': ai_label, 'LIMEOutput': [], 'rawPredictions': probs.tolist()}), 200

        # Otherwise run LIME
        lime_feats, fidelity = LIME_Algorithm(input_text)
        label_map = {0: 'Verified', 1: 'Fake'} # Assuming 0 and 1 are the primary labels
        ai_label = label_map.get(pred_label, "I don't know") # Default to "I don't know" if pred_label is unexpected

        response = {
            'AIResponse': ai_label,
            'LIMEOutput': lime_feats,
            'localFidelity': fidelity,
            'rawPredictions': probs.tolist(),
            'ood_score': mahalanobis_dist if 'mahalanobis_dist' in locals() else None
        }
        return jsonify(response), 200

    except Exception as e:
        print(f"Error processing request: {e}")
        # Print stack trace for more details
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # Create dummy OOD stats directory if it doesn't exist, so os.path.exists checks don't fail before load_model_and_ood_stats
    # This is mainly for local execution if the files aren't there.
    # In a deployed environment, these files should be part of the artifact.
    stats_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "ood_stats")
    if not os.path.exists(stats_dir):
        os.makedirs(stats_dir)
        print(f"Created directory for OOD stats: {stats_dir}")

    port = int(os.environ.get('PORT', 8080))
    # Ensure the model and stats are loaded before app runs in a __main__ context
    if tokenizer is None or model is None: # Basic check
        print("Model not loaded at startup, attempting to load now...")
        load_model_and_ood_stats() # Ensure it's loaded if script is run directly

    app.run(host='0.0.0.0', port=port)
